{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Predicting Time Series Data</h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Predicting data over time</h3>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introducing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1\n",
    "# Plot the raw values over time\n",
    "prices.plot()\n",
    "plt.show()\n",
    "\n",
    "# Part 2\n",
    "# Scatterplot with one company per axis\n",
    "prices.plot.scatter('EBAY', 'YHOO')\n",
    "plt.show()\n",
    "\n",
    "# Part 3\n",
    "# Scatterplot with color relating to time\n",
    "prices.plot.scatter('EBAY', 'YHOO', c = prices.index, \n",
    "                    cmap = plt.cm.viridis, colorbar = False)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting a simple regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Use stock symbols to extract training data\n",
    "X = all_prices[[\"EBAY\", \"NVDA\", \"YHOO\"]]\n",
    "y = all_prices[[\"AAPL\"]]\n",
    "\n",
    "# Fit and score the model with cross-validation\n",
    "scores = cross_val_score(Ridge(), X, y, cv = 3)\n",
    "print(scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing predicted values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Split our data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    train_size = .8, shuffle = False, random_state = 1)\n",
    "\n",
    "# Fit our model and generate predictions\n",
    "model = Ridge()\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "score = r2_score(y_test, predictions)\n",
    "print(score)\n",
    "\n",
    "# Part 2\n",
    "# Visualize our predictions along with the \"true\" values, and print the score\n",
    "fig, ax = plt.subplots(figsize = (15, 5))\n",
    "ax.plot(y_test, color = 'k', lw = 3)\n",
    "ax.plot(predictions, color = 'r', lw = 2)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Advanced time series prediction</h3>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing messy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices.plot(legend = False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Count the missing values of each time series\n",
    "missing_values = prices.isna().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputing missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1\n",
    "import pandas as pd\n",
    "# Create a function we'll use to interpolate and plot\n",
    "def interpolate_and_plot(prices, interpolation):\n",
    "\n",
    "    # Create a boolean mask for missing values\n",
    "    missing_values = prices.isna()\n",
    "\n",
    "    # Interpolate the missing values\n",
    "    prices_interp = prices.interpolate(interpolation)\n",
    "\n",
    "    # Plot the results, highlighting the interpolated values in black\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    prices_interp.plot(color = 'k', alpha = .6, ax = ax, legend = False)\n",
    "    \n",
    "    # Now plot the interpolated values on top in red\n",
    "    prices_interp[missing_values].plot(ax = ax, color = 'r', lw = 3, legend = False)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Part 2\n",
    "# Interpolate using the latest non-missing value\n",
    "interpolation_type = \"zero\"\n",
    "interpolate_and_plot(prices, interpolation_type)\n",
    "\n",
    "# Part 3\n",
    "# Interpolate linearly\n",
    "interpolation_type = 'linear'\n",
    "interpolate_and_plot(prices, interpolation_type)\n",
    "\n",
    "# Part 4\n",
    "# Interpolate with a quadratic function\n",
    "interpolation_type = \"quadratic\"\n",
    "interpolate_and_plot(prices, interpolation_type)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_change(series):\n",
    "    # Collect all *but* the last value of this window, then the final value\n",
    "    previous_values = series[:-1]\n",
    "    last_value = series[-1]\n",
    "\n",
    "    # Calculate the % difference between the last value and the mean of earlier values\n",
    "    percent_change = (last_value - np.mean(previous_values)) / np.mean(previous_values)\n",
    "    return percent_change\n",
    "\n",
    "# Apply your custom function and plot\n",
    "prices_perc = prices.rolling(20).apply(percent_change)\n",
    "prices_perc.loc[\"2014\":\"2015\"].plot()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_outliers(series):\n",
    "    # Calculate the absolute difference of each timepoint from the series mean\n",
    "    absolute_differences_from_mean = np.abs(series - np.mean(series))\n",
    "    \n",
    "    # Calculate a mask for the differences that are > 3 standard deviations from zero\n",
    "    this_mask = absolute_differences_from_mean > (np.std(series) * 3)\n",
    "    \n",
    "    # Replace these values with the median accross the data\n",
    "    series[this_mask] = np.nanmedian(series)\n",
    "    return series\n",
    "\n",
    "# Apply your preprocessing function to the timeseries and plot the results\n",
    "prices_perc = prices_perc.apply(replace_outliers)\n",
    "prices_perc.loc[\"2014\":\"2015\"].plot()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Creating features over time</h3>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Engineering multiple rolling features at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "percentiles = [1, 10, 25, 50, 75, 90, 99]\n",
    "\n",
    "# Use a list comprehension to create a partial function for each quantile\n",
    "percentile_functions = [partial(np.percentile, q = percentile) for percentile in percentiles]\n",
    "\n",
    "# Calculate each of these quantiles on the data using a rolling window\n",
    "prices_perc_rolling = prices_perc.rolling(20, min_periods = 5, closed = 'right')\n",
    "features_percentiles = prices_perc_rolling.aggregate(percentile_functions)\n",
    "\n",
    "# Plot a subset of the result\n",
    "ax = features_percentiles.loc[:\"2011-01\"].plot(cmap = plt.cm.viridis)\n",
    "ax.legend(percentiles, loc = (1.01, .5))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentiles and partial functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "percentiles = [1, 10, 25, 50, 75, 90, 99]\n",
    "\n",
    "# Use a list comprehension to create a partial function for each quantile\n",
    "percentile_functions = [partial(np.percentile, q = percentile) for percentile in percentiles]\n",
    "\n",
    "# Calculate each of these quantiles on the data using a rolling window\n",
    "prices_perc_rolling = prices_perc.rolling(20, min_periods = 5, closed = 'right')\n",
    "features_percentiles = prices_perc_rolling.aggregate(percentile_functions)\n",
    "\n",
    "# Plot a subset of the result\n",
    "ax = features_percentiles.loc[:\"2011-01\"].plot(cmap = plt.cm.viridis)\n",
    "ax.legend(percentiles, loc = (1.01, .5))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using \"date\" information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract date features from the data, add them as columns\n",
    "prices_perc['day_of_week'] = prices_perc.index.dayofweek\n",
    "prices_perc['week_of_year'] = prices_perc.index.weekofyear\n",
    "prices_perc['month_of_year'] = prices_perc.index.month\n",
    "\n",
    "# Print prices_perc\n",
    "print(prices_perc)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
