{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Validating and Inspecting Time Series Models</h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Creating features from the past</h3>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating time-shifted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# These are the \"time lags\"\n",
    "shifts = np.arange(1, 11).astype(int)\n",
    "\n",
    "# Use a dictionary comprehension to create name: value pairs, one pair per shift\n",
    "shifted_data = {\"lag_{}_day\".format(day_shift): prices_perc.shift(day_shift) for day_shift in shifts}\n",
    "\n",
    "# Convert into a DataFrame for subsequent use\n",
    "prices_perc_shifted = pd.DataFrame(shifted_data)\n",
    "\n",
    "# Plot the first 100 samples of each\n",
    "ax = prices_perc_shifted.iloc[:100].plot(cmap = plt.cm.viridis)\n",
    "prices_perc.iloc[:100].plot(color = 'r', lw = 2)\n",
    "ax.legend(loc = 'best')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Special case: Auto-regressive models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Replace missing values with the median for each column\n",
    "X = prices_perc_shifted.fillna(np.nanmedian(prices_perc_shifted))\n",
    "y = prices_perc.fillna(np.nanmedian(prices_perc))\n",
    "\n",
    "# Fit the model\n",
    "model = Ridge()\n",
    "model.fit(X, y)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize regression coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Part 1\n",
    "def visualize_coefficients(coefs, names, ax):\n",
    "    # Make a bar plot for the coefficients, including their names on the x-axis\n",
    "    ax.bar(names, coefs)\n",
    "    ax.set(xlabel = 'Coefficient name', ylabel = 'Coefficient value')\n",
    "    \n",
    "    # Set formatting so it looks nice\n",
    "    plt.setp(ax.get_xticklabels(), rotation = 45, horizontalalignment = 'right')\n",
    "    return ax\n",
    "\n",
    "# Part 2\n",
    "# Visualize the output data up to \"2011-01\"\n",
    "fig, axs = plt.subplots(2, 1, figsize = (10, 5))\n",
    "y.loc[:'2011-01'].plot(ax = axs[0])\n",
    "\n",
    "# Run the function to visualize model's coefficients\n",
    "visualize_coefficients(model.coef_, prices_perc_shifted.columns, ax = axs[1])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto-regression with a smoother time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize the output data up to \"2011-01\"\n",
    "fig, axs = plt.subplots(2, 1, figsize = (10, 5))\n",
    "y.loc[:'2011-01'].plot(ax = axs[0])\n",
    "\n",
    "# Run the function to visualize model's coefficients\n",
    "visualize_coefficients(model.coef_, prices_perc_shifted.columns, ax = axs[1])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Cross-validating time series data</h3>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation with shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import ShuffleSplit and create the cross-validation object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "cv = ShuffleSplit(n_splits = 10, random_state = 1)\n",
    "\n",
    "# Iterate through CV splits\n",
    "results = []\n",
    "for tr, tt in cv.split(X, y):\n",
    "    # Fit the model on training data\n",
    "    model.fit(X[tr], y[tr])\n",
    "    \n",
    "    # Generate predictions on the test data, score the predictions, and collect\n",
    "    prediction = model.predict(X[tt])\n",
    "    score = r2_score(y[tt], prediction)\n",
    "    results.append((prediction, score, tt))\n",
    "\n",
    "# Custom function to quickly visualize predictions\n",
    "visualize_predictions(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation without shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create KFold cross-validation object\n",
    "from sklearn.model_selection import KFold\n",
    "cv = KFold(n_splits = 10, shuffle = False)\n",
    "\n",
    "# Iterate through CV splits\n",
    "results = []\n",
    "for tr, tt in cv.split(X, y):\n",
    "    # Fit the model on training data\n",
    "    model.fit(X[tr], y[tr])\n",
    "    \n",
    "    # Generate predictions on the test data and collect\n",
    "    prediction = model.predict(X[tt])\n",
    "    results.append((prediction, tt))\n",
    "    \n",
    "# Custom function to quickly visualize predictions\n",
    "visualize_predictions(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time-based cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import TimeSeriesSplit\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# Create time-series cross-validation object\n",
    "cv = TimeSeriesSplit(n_splits = 10)\n",
    "\n",
    "# Iterate through CV splits\n",
    "fig, ax = plt.subplots()\n",
    "for ii, (tr, tt) in enumerate(cv.split(X, y)):\n",
    "    # Plot the training data on each iteration, to see the behavior of the CV\n",
    "    ax.plot(tr, ii + y[tr])\n",
    "\n",
    "ax.set(title='Training data on each CV iteration', ylabel='CV iteration')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Stationarity and stability</h3>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "First, let's confirm what we know about stationarity. Take a look at these time series.\n",
    "Which of the following time series do you think are not stationary?\n",
    "Ans: B and C, Option: 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrapping a confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "def bootstrap_interval(data, percentiles = (2.5, 97.5), n_boots = 100):\n",
    "    \"\"\"Bootstrap a confidence interval for the mean of columns of a 2-D dataset.\"\"\"\n",
    "    # Create our empty array to fill the results\n",
    "    bootstrap_means = np.zeros([n_boots, data.shape[-1]])\n",
    "    for ii in range(n_boots):\n",
    "        # Generate random indices for our data *with* replacement, then take the sample mean\n",
    "        random_sample = resample(data)\n",
    "        bootstrap_means[ii] = random_sample.mean(axis = 0)\n",
    "        \n",
    "    # Compute the percentiles of choice for the bootstrapped means\n",
    "    percentiles = np.percentile(bootstrap_means, percentiles, axis = 0)\n",
    "    return percentiles"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating variability in model coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Part 1\n",
    "# Iterate through CV splits\n",
    "n_splits = 100\n",
    "cv = TimeSeriesSplit(n_splits = n_splits)\n",
    "\n",
    "# Create empty array to collect coefficients\n",
    "coefficients = np.zeros([n_splits, X.shape[1]])\n",
    "\n",
    "for ii, (tr, tt) in enumerate(cv.split(X, y)):\n",
    "    # Fit the model on training data and collect the coefficients\n",
    "    model.fit(X[tr], y[tr])\n",
    "    coefficients[ii] = model.coef_\n",
    "\n",
    "# Part 2\n",
    "# Calculate a confidence interval around each coefficient\n",
    "bootstrapped_interval = bootstrap_interval(coefficients)\n",
    "\n",
    "# Plot it\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(feature_names, bootstrapped_interval[0], marker = '_', lw = 3)\n",
    "ax.scatter(feature_names, bootstrapped_interval[1], marker = '_', lw = 3)\n",
    "ax.set(title = '95% confidence interval for model coefficients')\n",
    "plt.setp(ax.get_xticklabels(), rotation = 45, horizontalalignment = 'right')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing model score variability over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Part 1\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Generate scores for each split to see how the model performs over time\n",
    "scores = cross_val_score(model, X, y, cv=cv, scoring=my_pearsonr)\n",
    "\n",
    "# Convert to a Pandas Series object\n",
    "scores_series = pd.Series(scores, index=times_scores, name='score')\n",
    "\n",
    "# Bootstrap a rolling confidence interval for the mean score\n",
    "scores_lo = scores_series.rolling(20).aggregate(partial(bootstrap_interval, percentiles = 2.5))\n",
    "scores_hi = scores_series.rolling(20).aggregate(partial(bootstrap_interval, percentiles = 97.5))\n",
    "\n",
    "# Part 2\n",
    "# Plot the results\n",
    "fig, ax = plt.subplots()\n",
    "scores_lo.plot(ax = ax, label = \"Lower confidence interval\")\n",
    "scores_hi.plot(ax = ax, label = \"Upper confidence interval\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accounting for non-stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Part 1\n",
    "# Pre-initialize window sizes\n",
    "window_sizes = [25, 50, 75, 100]\n",
    "\n",
    "# Create an empty DataFrame to collect the stores\n",
    "all_scores = pd.DataFrame(index = times_scores)\n",
    "\n",
    "# Generate scores for each split to see how the model performs over time\n",
    "for window in window_sizes:\n",
    "    # Create cross-validation object using a limited lookback window\n",
    "    cv = TimeSeriesSplit(n_splits=100, max_train_size=window)\n",
    "    \n",
    "    # Calculate scores across all CV splits and collect them in a DataFrame\n",
    "    this_scores = cross_val_score(model, X, y, cv = cv, scoring = my_pearsonr)\n",
    "    all_scores['Length {}'.format(window)] = this_scores\n",
    "\n",
    "# Part 2\n",
    "# Visualize the scores\n",
    "ax = all_scores.rolling(10).mean().plot(cmap = plt.cm.coolwarm)\n",
    "ax.set(title = 'Scores for multiple windows', ylabel = 'Correlation (r)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
